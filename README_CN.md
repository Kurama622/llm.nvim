<p align="center">
  <img src="https://github.com/Kurama622/screenshot/raw/master/llm/llm-logo-light-purple-font.png" alt="llm.nvim" width="345">
</p>
<p align="center">
  <a href="README.md">English</a> |
  <a href="README_CN.md"><b>ç®€ä½“ä¸­æ–‡</b></a>
</p>

---

> [!IMPORTANT]
> å…è´¹çš„å¤§è¯­è¨€æ¨¡å‹æ’ä»¶ï¼Œè®©ä½ åœ¨Neovimä¸­ä¸å¤§æ¨¡å‹äº¤äº’
>
> 1. æ”¯æŒä»»æ„ä¸€æ¬¾å¤§æ¨¡å‹ï¼Œæ¯”å¦‚gptï¼Œglmï¼Œkimiã€deepseekæˆ–è€…æœ¬åœ°è¿è¡Œçš„å¤§æ¨¡å‹(æ¯”å¦‚ollama)
>
> 2. æ”¯æŒå®šä¹‰å±äºä½ è‡ªå·±çš„AIå·¥å…·ï¼Œä¸”ä¸åŒå·¥å…·å¯ä»¥ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
>
> 3. æœ€é‡è¦çš„ä¸€ç‚¹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»»ä½•å¹³å°æä¾›çš„å…è´¹æ¨¡å‹ï¼ˆæ¯”å¦‚`Cloudflare`ï¼Œ`Github models`ï¼Œ`siliconflow`ã€`openrouter`æˆ–è€…å…¶ä»–çš„å¹³å°ï¼‰


# ç›®å½•
<!-- mtoc-start -->

* [æˆªå›¾](#æˆªå›¾)
* [å®‰è£…](#å®‰è£…)
  * [ä¾èµ–](#ä¾èµ–)
  * [å‡†å¤‡å·¥ä½œ](#å‡†å¤‡å·¥ä½œ)
    * [Cloudflare](#cloudflare)
    * [ChatGLM (æ™ºè°±æ¸…è¨€)](#chatglm-æ™ºè°±æ¸…è¨€)
    * [kimi (æœˆä¹‹æš—é¢)](#kimi-æœˆä¹‹æš—é¢)
    * [Github Models](#github-models)
    * [siliconflow (ç¡…åŸºæµåŠ¨)](#siliconflow-ç¡…åŸºæµåŠ¨)
    * [Deepseek](#deepseek)
    * [openrouter](#openrouter)
    * [æœ¬åœ°è¿è¡Œçš„å¤§æ¨¡å‹](#æœ¬åœ°è¿è¡Œçš„å¤§æ¨¡å‹)
  * [åŸºæœ¬é…ç½®](#åŸºæœ¬é…ç½®)
  * [çª—å£é£æ ¼é…ç½®](#çª—å£é£æ ¼é…ç½®)
  * [AIå·¥å…·çš„é…ç½®](#aiå·¥å…·çš„é…ç½®)
  * [æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹](#æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹)
* [é»˜è®¤å¿«æ·é”®](#é»˜è®¤å¿«æ·é”®)
* [ä½œè€…çš„é…ç½®æ–‡ä»¶](#ä½œè€…çš„é…ç½®æ–‡ä»¶)
* [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
  * [windowsçš„curlä½¿ç”¨æ ¼å¼ä¸linuxä¸ä¸€æ ·ï¼Œllm.nvimé»˜è®¤çš„è¯·æ±‚æ ¼å¼ï¼Œwindowsä¸‹ä¼šæœ‰é—®é¢˜](#windowsçš„curlä½¿ç”¨æ ¼å¼ä¸linuxä¸ä¸€æ ·llmnvimé»˜è®¤çš„è¯·æ±‚æ ¼å¼windowsä¸‹ä¼šæœ‰é—®é¢˜)
  * [å¤šä¸ªå¤§æ¨¡å‹åˆ‡æ¢ï¼Œé¢‘ç¹æ›´æ”¹LLM_KEYçš„å€¼å¾ˆéº»çƒ¦ï¼Œè€Œä¸”æˆ‘ä¸æƒ³åœ¨Neovimçš„é…ç½®æ–‡ä»¶ä¸­æš´éœ²æˆ‘çš„Key](#å¤šä¸ªå¤§æ¨¡å‹åˆ‡æ¢é¢‘ç¹æ›´æ”¹llm_keyçš„å€¼å¾ˆéº»çƒ¦è€Œä¸”æˆ‘ä¸æƒ³åœ¨neovimçš„é…ç½®æ–‡ä»¶ä¸­æš´éœ²æˆ‘çš„key)
  * [ä¸åŒè§£æå‡½æ•°çš„ä¼˜å…ˆçº§](#ä¸åŒè§£æå‡½æ•°çš„ä¼˜å…ˆçº§)
  * [AIç”Ÿæˆgit commitä¿¡æ¯çš„åŠŸèƒ½å¦‚ä½•ä¸lazygité›†æˆåœ¨ä¸€èµ·?](#aiç”Ÿæˆgit-commitä¿¡æ¯çš„åŠŸèƒ½å¦‚ä½•ä¸lazygité›†æˆåœ¨ä¸€èµ·)

<!-- mtoc-end -->

## æˆªå›¾

1. **èŠå¤©ç•Œé¢**

<p align= "center">
  <img src="https://github.com/Kurama622/screenshot/blob/master/llm/llm-chat-compress.png" alt="llm-chat" width="560">
</p>

2. **å¿«é€Ÿç¿»è¯‘**
<p align= "center">
  <img src="https://github.com/user-attachments/assets/4c98484a-f0af-45ae-9b62-ea0069ccbf60" alt="llm-translate" width="560">
</p>

3. **è§£é‡Šä»£ç **
<p align= "center">
  <img src="https://github.com/Kurama622/screenshot/blob/master/llm/llm-explain-code-compress.png" alt="llm-explain-code" width="560">
</p>

4. **ä¼˜åŒ–ä»£ç **
  - **å¹¶æ’å±•ç¤º**
  <p align= "center">
    <img src="https://github.com/Kurama622/screenshot/blob/master/llm/llm-optimize-code-compress.png" alt="llm-optimize-code" width="560">
  </p>

  - **ä»¥diffçš„å½¢å¼å±•ç¤º**
  <p align= "center">
    <img src="https://github.com/user-attachments/assets/35c105b3-a2a9-4a6c-887c-cb20b77b3264" alt="llm-optimize-compare-action" width="560">
  </p>

5. **ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹**
<p align= "center">
  <img src="https://github.com/user-attachments/assets/b288e3c9-7d25-40cb-8645-14dacb571529" alt="test-case" width="560">
</p>

6. **AIç¿»è¯‘**
<p align= "center">
  <img src="https://github.com/user-attachments/assets/ff90b1b4-3c2c-40e6-9321-4bab134710ec" alt="llm-trans" width="560">
</p>

7. **ç”Ÿæˆgit commitä¿¡æ¯**
<p align= "center">
  <img src="https://github.com/user-attachments/assets/261b21c5-0df0-48c2-916b-07f5ce0c981d" alt="llm-git-commit-msg" width="560">
</p>

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

## å®‰è£…

### ä¾èµ–

- `curl`: è¯·è‡ªè¡Œå®‰è£…

### å‡†å¤‡å·¥ä½œ

#### Cloudflare

1. æ³¨å†Œ[cloudflare](https://dash.cloudflare.com/)ï¼Œè·å–è´¦æˆ·å’ŒAPI Key. ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://developers.cloudflare.com/workers-ai/models/)çœ‹åˆ°cloudflareçš„æ‰€æœ‰æ¨¡å‹, å…¶ä¸­æ ‡æ³¨betaçš„æ˜¯å…è´¹æ¨¡å‹.

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`ACCOUNT` å’Œ `LLM_KEY`ç¯å¢ƒå˜é‡

```bash
export ACCOUNT=<Your ACCOUNT>
export LLM_KEY=<Your API_KEY>
```
#### ChatGLM (æ™ºè°±æ¸…è¨€)

1. æ³¨å†Œæ™ºè°±æ¸…è¨€ï¼š[https://open.bigmodel.cn/](https://open.bigmodel.cn/), è·å–ä½ çš„API Key.

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`
```bash
export LLM_KEY=<Your API_KEY>
```

#### kimi (æœˆä¹‹æš—é¢)
1. æ³¨å†Œæœˆä¹‹æš—é¢: [Moonshot AI å¼€æ”¾å¹³å°](https://login.moonshot.cn/?source=https%3A%2F%2Fplatform.moonshot.cn%2Fredirect&appid=dev-workbench), è·å–ä½ çš„API Key.

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`
```bash
export LLM_KEY=<Your API_KEY>
```

#### Github Models
1. è·å–ä½ çš„Github [Token](https://github.com/settings/tokens)

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`
```bash
export LLM_KEY=<Github Token>
```

#### siliconflow (ç¡…åŸºæµåŠ¨)
1. æ³¨å†Œç¡…åŸºæµåŠ¨ï¼š[siliconflow](https://account.siliconflow.cn/login?redirect=https%3A%2F%2Fcloud.siliconflow.cn%2F%3F), è·å–ä½ çš„API Key. ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://cloud.siliconflow.cn/models)çœ‹åˆ°ç¡…åŸºæµåŠ¨ä¸Šæ‰€æœ‰çš„æ¨¡å‹ï¼Œé€‰æ‹©`åªçœ‹å…è´¹`å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„å…è´¹æ¨¡å‹

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`
```bash
export LLM_KEY=<Your API_KEY>
```

#### Deepseek
1. æ³¨å†ŒDeepseek: [deepseek](https://platform.deepseek.com/api_keys), è·å–ä½ çš„API Key.

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`
```bash
export LLM_KEY=<Your API_KEY>
```

#### openrouter
1. æ³¨å†Œopenrouterï¼š[openrouter](https://openrouter.ai/), è·å–ä½ çš„API Key.

2. åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`
```bash
export LLM_KEY=<Your API_KEY>
```

#### æœ¬åœ°è¿è¡Œçš„å¤§æ¨¡å‹
åœ¨ä½ çš„`zshrc`æˆ–è€…`bashrc`ä¸­è®¾ç½®`LLM_KEY`ä¸º`NONE`
```bash
export LLM_KEY=NONE
```

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### åŸºæœ¬é…ç½®

**ä¸€äº›ä½ åº”è¯¥çŸ¥é“çš„å‘½ä»¤**

- `LLMSessionToggle`: æ‰“å¼€/éšè—å¯¹è¯ç•Œé¢
- `LLMSelectedTextHandler`: å¯¹é€‰ä¸­çš„æ–‡æœ¬è¿›è¡Œå¤„ç†ï¼Œå¦‚ä½•å¤„ç†å–å†³äºä½ ä¼ å…¥ä»€ä¹ˆæç¤ºè¯
- `LLMAppHandler`: è°ƒç”¨AIå·¥å…·

> å¦‚æœurlæ²¡æœ‰è¢«é…ç½®ï¼Œé»˜è®¤ä½¿ç”¨Cloudflare

```lua
  {
    "Kurama622/llm.nvim",
    dependencies = { "nvim-lua/plenary.nvim", "MunifTanjim/nui.nvim" },
    cmd = { "LLMSesionToggle", "LLMSelectedTextHandler" },
    config = function()
      require("llm").setup({
        prompt = "You are a helpful chinese assistant.",

        prefix = {
          user = { text = "ğŸ˜ƒ ", hl = "Title" },
          assistant = { text = "âš¡ ", hl = "Added" },
        },

        style = "float", -- right | left | above | below | float

        -- [[ Github Models ]]
        url = "https://models.inference.ai.azure.com/chat/completions",
        model = "gpt-4o",
        api_type = "openai",
        --[[ å¯é€‰çš„: å¦‚æœä½ éœ€è¦åŒæ—¶ä½¿ç”¨ä¸åŒå¹³å°çš„æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡é…ç½®
                     fetch_key æ¥ä¿è¯ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„API Key]]
        fetch_key = function()
          return switch("enable_gpt")
        end,

        -- [[ cloudflare ]]
        -- model = "@cf/google/gemma-7b-it-lora",

        -- [[ ChatGLM ]]
        -- url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
        -- model = "glm-4-flash",

        -- [[ kimi ]]
        -- url = "https://api.moonshot.cn/v1/chat/completions",
        -- model = "moonshot-v1-8k", -- "moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"
        -- api_type = "openai",

        -- [[ local llm ]]
        -- url = "http://localhost:11434/api/chat",
        -- model = "llama3.2:1b",
        -- api_type = "ollama",

        -- [[ siliconflow ]]
        -- url = "https://api.siliconflow.cn/v1/chat/completions",
        -- api_type = "openai",
        -- model = "Qwen/Qwen2.5-7B-Instruct",
        -- -- [optional: fetch_key]
        -- fetch_key = function()
        --   return switch("enable_siliconflow")
        -- end,

        -- [[ openrouter ]]
        -- url = "https://openrouter.ai/api/v1/chat/completions",
        -- model = "google/gemini-2.0-flash-exp:free",
        -- api_type = "openai",
        -- fetch_key = function()
        --   return switch("enable_openrouter")
        -- end,

        -- [[deepseek]]
        -- url = "https://api.deepseek.com/chat/completions",
        -- model = "deepseek-chat",
        -- api_type = "openai",
        -- fetch_key = function()
        --   return switch("enable_deepseek")
        -- end,

        max_tokens = 1024,
        save_session = true,
        max_history = 15,
        history_path = "/tmp/history",    -- where to save history
        temperature = 0.3,
        top_p = 0.7,

        spinner = {
          text = {
            "î©±ó°§ó°§",
            "ó°§î©±ó°§",
            "ó°§ó°§î©±",
            "ó°§î©±ó°§",
          },
          hl = "Title",
        },

        display = {
          diff = {
            layout = "vertical", -- vertical|horizontal split for default provider
            opts = { "internal", "filler", "closeoff", "algorithm:patience", "followwrap", "linematch:120" },
            provider = "mini_diff", -- default|mini_diff
          },
        },

        -- stylua: ignore
        keys = {
          -- The keyboard mapping for the input window.
          ["Input:Cancel"]      = { mode = "n", key = "<C-c>" },
          ["Input:Submit"]      = { mode = "n", key = "<cr>" },
          ["Input:Resend"]      = { mode = "n", key = "<C-r>" },

          -- only works when "save_session = true"
          ["Input:HistoryNext"] = { mode = "n", key = "<C-j>" },
          ["Input:HistoryPrev"] = { mode = "n", key = "<C-k>" },

          -- The keyboard mapping for the output window in "split" style.
          ["Output:Ask"]        = { mode = "n", key = "i" },
          ["Output:Cancel"]     = { mode = "n", key = "<C-c>" },
          ["Output:Resend"]     = { mode = "n", key = "<C-r>" },

          -- The keyboard mapping for the output and input windows in "float" style.
          ["Session:Toggle"]    = { mode = "n", key = "<leader>ac" },
          ["Session:Close"]     = { mode = "n", key = "<esc>" },
        },
      })
    end,
    keys = {
      { "<leader>ac", mode = "n", "<cmd>LLMSessionToggle<cr>" },
      { "<leader>ae", mode = "v", "<cmd>LLMSelectedTextHandler è¯·è§£é‡Šä¸‹é¢è¿™æ®µä»£ç <cr>" },
      { "<leader>t", mode = "x", "<cmd>LLMSelectedTextHandler è‹±è¯‘æ±‰<cr>" },
    },
  },
```

- `prompt`: æ¨¡å‹çš„æç¤ºè¯
- `prefix`: å¯¹è¯è§’è‰²çš„æ ‡å¿—
- `style`: å¯¹è¯çª—å£çš„æ ·å¼(floatå³æµ®åŠ¨çª—å£ï¼Œå…¶ä»–å‡ä¸ºåˆ†å‰²çª—å£)
- `url`: æ¨¡å‹çš„APIåœ°å€
- `model`: æ¨¡å‹çš„åç§°
- `api_type`: æ¨¡å‹è¾“å‡ºçš„è§£ææ ¼å¼: `openai`, `zhipu`, `ollama`, `workers-ai`. `openai`çš„æ ¼å¼å¯ä»¥å…¼å®¹å¤§éƒ¨åˆ†çš„æ¨¡å‹ï¼Œä½†`ChatGLM`åªèƒ½ç”¨`zhipu`çš„æ ¼å¼å»è§£æï¼Œ`cloudflare`åªèƒ½ç”¨`workers-ai`å»è§£æã€‚å¦‚æœä½ ä½¿ç”¨ollamaæ¥è¿è¡Œæ¨¡å‹ï¼Œä½ å¯ä»¥é…ç½®`ollama`ã€‚
- `fetch_key`: å¦‚æœä½ éœ€è¦åŒæ—¶ä½¿ç”¨ä¸åŒå¹³å°çš„æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡é…ç½®`fetch_key`æ¥ä¿è¯ä¸åŒæ¨¡å‹ä½¿ç”¨ä¸åŒçš„API Keyï¼Œç”¨æ³•å¦‚ä¸‹ï¼š
  ```lua
  fetch_key = function() return "<your api key>" end
  ```
- `max_tokens`: æ¨¡å‹çš„æœ€å¤§è¾“å‡ºé•¿åº¦
- `save_session`: æ˜¯å¦ä¿å­˜ä¼šè¯å†å²
- `max_history`: æœ€å¤šä¿å­˜å¤šå°‘ä¸ªä¼šè¯
- `history_path`: ä¼šè¯å†å²çš„ä¿å­˜è·¯å¾„
- `temperature`: æ¨¡å‹çš„temperature, æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§
- `top_p`: æ¨¡å‹çš„top_p, æ§åˆ¶æ¨¡å‹è¾“å‡ºçš„éšæœºæ€§
- `spinner`: æ¨¡å‹è¾“å‡ºçš„ç­‰å¾…åŠ¨ç”» (éæµå¼è¾“å‡ºæ—¶ç”Ÿæ•ˆ)
- `display`
  - `diff`: diffçš„æ˜¾ç¤ºé£æ ¼ï¼ˆä¼˜åŒ–ä»£ç å¹¶æ˜¾ç¤ºdiffæ—¶ç”Ÿæ•ˆ, æˆªå›¾ä¸­çš„é£æ ¼ä¸ºmini_diff, éœ€è¦å®‰è£…[mini.diff](https://github.com/echasnovski/mini.diff)ï¼‰

- `keys`: ä¸åŒçª—å£çš„å¿«æ·é”®è®¾ç½®ï¼Œé»˜è®¤å€¼è§[é»˜è®¤å¿«æ·é”®](#é»˜è®¤å¿«æ·é”®)
  - *æµ®åŠ¨çª—å£é£æ ¼ä¸‹çš„å¿«æ·é”®*
    - è¾“å…¥çª—å£
      - `Input:Cancel`: å–æ¶ˆå¯¹è¯
      - `Input:Submit`: æäº¤é—®é¢˜
      - `Input:Resend`: é‡æ–°å›ç­”
      - `Input:HistoryNext`: åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªä¼šè¯å†å²
      - `Input:HistoryPrev`: åˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªä¼šè¯å†å²
    - æ•´ä¸ªå¯¹è¯ç•Œé¢
      - `Session:Toggle`: æ‰“å¼€/éšè—å¯¹è¯ç•Œé¢
      - `Session:Close`: å…³é—­å¯¹è¯ç•Œé¢
  - *åˆ†å‰²çª—å£é£æ ¼ä¸‹çš„å¿«æ·é”®*
    - è¾“å‡ºçª—å£
      - `Output:Ask`: æ‰“å¼€è¾“å…¥çª—å£
      - `Output:Cancel`: å–æ¶ˆå¯¹è¯
      - `Output:Resend`: é‡æ–°å›ç­”

å¦‚æœä½ ä½¿ç”¨æœ¬åœ°è¿è¡Œçš„å¤§æ¨¡å‹ï¼ˆä½†ä¸æ˜¯ç”¨ollamaè¿è¡Œçš„ï¼‰ï¼Œä½ å¯èƒ½éœ€è¦å®šä¹‰streaming_handlerï¼ˆå¿…é¡»ï¼‰ï¼Œä»¥åŠparse_handlerï¼ˆéå¿…éœ€ï¼Œåªæœ‰ä¸ªåˆ«AIå·¥å…·ä¼šç”¨åˆ°ï¼‰ï¼Œå…·ä½“è§[æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹](#æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹)

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### çª—å£é£æ ¼é…ç½®

å¦‚æœä½ æƒ³è¿›ä¸€æ­¥é…ç½®å¯¹è¯ç•Œé¢çš„æ ·å¼ï¼Œä½ å¯ä»¥åˆ†åˆ«å¯¹`input_box_opts`ã€`output_box_opts`ã€`history_box_opts`å’Œ`popwin_opts`è¿›è¡Œé…ç½®ã€‚

å®ƒä»¬çš„é…ç½®é¡¹éƒ½æ˜¯ç›¸åŒçš„ï¼š
- `relative`:
  - `editor`: è¯¥æµ®åŠ¨çª—å£ç›¸å¯¹äºå½“å‰ç¼–è¾‘å™¨çª—å£
  - `cursor`: è¯¥æµ®åŠ¨çª—å£ç›¸å¯¹äºå½“å‰å…‰æ ‡ä½ç½®
  - `win` : è¯¥æµ®åŠ¨çª—å£ç›¸å¯¹äºå½“å‰çª—å£

- `position`: çª—å£çš„ä½ç½®
- `size`: çª—å£çš„å¤§å°
- `enter`: çª—å£æ˜¯å¦è‡ªåŠ¨è·å¾—ç„¦ç‚¹
- `focusable`: çª—å£æ˜¯å¦å¯ä»¥è·å¾—ç„¦ç‚¹
- `zindex`: çª—å£çš„å±‚çº§
- `border` 
  - `style`: çª—å£çš„è¾¹æ¡†æ ·å¼
  - `text`: çª—å£çš„è¾¹æ¡†æ–‡æœ¬
- `win_options`: çª—å£çš„é€‰é¡¹
 - `winblend`: çª—å£çš„é€æ˜åº¦
 - `winhighlight`: çª—å£çš„é«˜äº®

æ›´å¤šä¿¡æ¯å¯ä»¥æŸ¥é˜…[nui/popup](https://github.com/MunifTanjim/nui.nvim/blob/main/lua/nui/popup/README.md)

```lua
  {
    "Kurama622/llm.nvim",
    dependencies = { "nvim-lua/plenary.nvim", "MunifTanjim/nui.nvim" },
    cmd = { "LLMSesionToggle", "LLMSelectedTextHandler" },
    config = function()
      require("llm").setup({
        style = "float", -- right | left | above | below | float

        -- [[ Github Models ]]
        url = "https://models.inference.ai.azure.com/chat/completions",
        model = "gpt-4o",
        api_type = "openai",

        input_box_opts = {
          relative = "editor",
          position = {
            row = "85%",
            col = 15,
          },
          size = {
            height = "5%",
            width = 120,
          },

          enter = true,
          focusable = true,
          zindex = 50,
          border = {
            style = "rounded",
            text = {
              top = " Enter Your Question ",
              top_align = "center",
            },
          },
          win_options = {
            -- set window transparency
            winblend = 20,
            -- set window highlight
            winhighlight = "Normal:Normal,FloatBorder:FloatBorder",
          },
        },
        output_box_opts = {
          relative = "editor",
          position = {
            row = "35%",
            col = 15,
          },
          size = {
            height = "65%",
            width = 90,
          },
          enter = true,
          focusable = true,
          zindex = 20,
          border = {
            style = "rounded",
            text = {
              top = " Preview ",
              top_align = "center",
            },
          },
          win_options = {
            winblend = 20,
            winhighlight = "Normal:Normal,FloatBorder:FloatBorder",
          },
        },

        history_box_opts = {
          relative = "editor",
          position = {
            row = "35%",
            col = 108,
          },
          size = {
            height = "65%",
            width = 27,
          },
          zindex = 70,
          enter = false,
          focusable = false,
          border = {
            style = "rounded",
            text = {
              top = " History ",
              top_align = "center",
            },
          },
          win_options = {
            winblend = 20,
            winhighlight = "Normal:Normal,FloatBorder:FloatBorder",
          },
        },

        -- LLMSelectedTextHandler windows options
        popwin_opts = {
          relative = "cursor",
          position = {
            row = -7,
            col = 20,
          },
          size = {
            width = "50%",
            height = 15,
          },
          enter = true,
          border = {
            style = "rounded",
            text = {
              top = " Explain ",
            },
          },
        },
      })
    end,
    keys = {
      { "<leader>ac", mode = "n", "<cmd>LLMSessionToggle<cr>" },
      { "<leader>ae", mode = "v", "<cmd>LLMSelectedTextHandler è¯·è§£é‡Šä¸‹é¢è¿™æ®µä»£ç <cr>" },
      { "<leader>t", mode = "x", "<cmd>LLMSelectedTextHandler è‹±è¯‘æ±‰<cr>" },
    },
  },
```

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### AIå·¥å…·çš„é…ç½®

ç›®å‰llm.nvimæä¾›äº†ä¸€äº›AIå·¥å…·çš„æ¨¡æ¿ï¼Œæ–¹ä¾¿å¤§å®¶å»è‡ªå®šä¹‰è‡ªå·±çš„AIå·¥å…·

æ‰€æœ‰çš„AIå·¥å…·éƒ½éœ€è¦å®šä¹‰åœ¨`app_handler`ä¸­ï¼Œä»¥ä¸€å¯¹`key-value`çš„å½¢å¼å‘ˆç°ï¼Œ`key`ä¸ºå·¥å…·åç§°ï¼Œ`value`ä¸ºå·¥å…·çš„é…ç½®ä¿¡æ¯

å¯¹äºæ‰€æœ‰çš„AIå·¥å…·ï¼Œå®ƒä»¬çš„é…ç½®é¡¹éƒ½æ˜¯åŸºæœ¬ç±»ä¼¼çš„:

- `handler`: ä½¿ç”¨å“ªä¸ªæ¨¡æ¿
  - `side_by_side_handler`: ä¸¤ä¸ªçª—å£å¹¶æ’å±•ç¤ºç»“æœ
  - `action_handler`: åœ¨æºæ–‡ä»¶ä¸­ä»¥diffçš„å½¢å¼å±•ç¤ºç»“æœ
    - `Y`/`y`: æ¥å—LLMå»ºè®®ä»£ç 
    - `N`/`n`: æ‹’ç»LLMå»ºè®®ä»£ç 
    - `<ESC>`: ç›´æ¥é€€å‡º
    - `I/i`: è¾“å…¥ä¼˜åŒ–çš„è¡¥å……æ¡ä»¶
    - `<C-r>`: ç›´æ¥é‡æ–°ä¼˜åŒ–
  - `qa_handler`: å•è½®å¯¹è¯çš„AI
  - `flexi_handler`: ç»“æœä¼šå±•ç¤ºåœ¨å¼¹æ€§çª—å£ä¸­ ( æ ¹æ®è¾“å‡ºæ–‡æœ¬çš„å†…å®¹å¤šå°‘è‡ªåŠ¨è®¡ç®—çª—å£å¤§å° )
  - ä½ ä¹Ÿå¯ä»¥è‡ªå®šä¹‰å‡½æ•°
- `prompt`: AIå·¥å…·çš„æç¤ºè¯
- `opts`
  - `spell`: æ˜¯å¦æœ‰æ‹¼å†™æ£€æŸ¥
  - `number`: æ˜¯å¦æ˜¾ç¤ºè¡Œå·
  - `wrap`: æ˜¯å¦è‡ªåŠ¨æ¢è¡Œ
  - `linebreak`: æ˜¯å¦å…è®¸ä»å•è¯ä¸­é—´æ¢è¡Œ
  - `url`ã€`model`: è¯¥AIå·¥å…·ä½¿ç”¨å“ªä¸ªå¤§æ¨¡å‹
  - `api_type`: è¯¥AIå·¥å…·è¾“å‡ºçš„è§£æç±»å‹
  - `streaming_handler`: è¯¥AIå·¥å…·ä½¿ç”¨è‡ªå®šä¹‰çš„æµè§£æå‡½æ•°
  - `parse_handler`: è¯¥AIå·¥å…·ä½¿ç”¨è‡ªå®šä¹‰çš„è§£æå‡½æ•°
  - `border`ï¼šæµ®åŠ¨çª—å£çš„è¾¹æ¡†æ ·å¼
  - `accept`
    - `mapping`: æ¥å—AIè¾“å‡ºçš„æŒ‰é”®æ˜ å°„
      - `mode`: æ˜ å°„å¯¹åº”çš„vimæ¨¡å¼, é»˜è®¤ä¸º`n`
      - `keys`: ä½ çš„æŒ‰é”®, é»˜è®¤ä¸º`Y`/`y`
    - `action`: æ¥å—AIè¾“å‡ºæ—¶æ‰§è¡Œçš„å‡½æ•°ï¼Œé»˜è®¤æ˜¯å¤åˆ¶åˆ°å‰ªè´´æ¿
  - `reject`
    - `mapping`: æ‹’ç»AIè¾“å‡ºçš„æŒ‰é”®æ˜ å°„
      - `mode`: æ˜ å°„å¯¹åº”çš„vimæ¨¡å¼, é»˜è®¤ä¸º`n`
      - `keys`: ä½ çš„æŒ‰é”®, é»˜è®¤ä¸º`N`/`n`
    - `action`: æ‹’ç»AIè¾“å‡ºæ—¶æ‰§è¡Œçš„å‡½æ•°ï¼Œé»˜è®¤æ˜¯ä»€ä¹ˆä¹Ÿä¸åšæˆ–è€…å…³é—­AIå·¥å…·çª—å£
  - `close`
    - `mapping`: å…³é—­AIå·¥å…·çš„æŒ‰é”®æ˜ å°„
      - `mode`: æ˜ å°„å¯¹åº”çš„vimæ¨¡å¼, é»˜è®¤ä¸º`n`
      - `keys`: ä½ çš„æŒ‰é”®, é»˜è®¤ä¸º`<ESC>`
    - `action`: å…³é—­AIå·¥å…·ï¼Œé»˜è®¤æ˜¯æ‹’ç»æ‰€æœ‰AIè¾“å‡ºå¹¶å…³é—­AIå·¥å…·çª—å£

**ä¸åŒæ¨¡æ¿è¿˜æœ‰ä¸€äº›å±äºè‡ªå·±çš„ä¸“å±é…ç½®é¡¹**

- `qa_handler`çš„`opts`ä¸­ä½ è¿˜å¯ä»¥å®šä¹‰ï¼š
  - `component_width`: ç»„ä»¶çš„å®½åº¦
  - `component_height`: ç»„ä»¶çš„é«˜åº¦
  - `query`
      - `title`: ç»„ä»¶çš„æ ‡é¢˜ï¼Œä¼šæ˜¾ç¤ºåœ¨ç»„ä»¶ä¸Šæ–¹å±…ä¸­å¤„
      - `hl` : æ ‡é¢˜çš„é«˜äº®
  - `input_box_opts`: è¾“å…¥æ¡†çš„çª—å£é€‰é¡¹ï¼ˆ`size`, `win_options`ï¼‰
  - `preview_box_opts`: é¢„è§ˆæ¡†çš„çª—å£é€‰é¡¹ï¼ˆ`size`, `win_options`ï¼‰

- `action_handler`çš„`opts`ä¸­ä½ è¿˜å¯ä»¥å®šä¹‰:
  - `language`: è¾“å‡ºç»“æœä½¿ç”¨çš„è¯­è¨€ï¼ˆ`English`/`Chinese`/`Japanese`ç­‰ï¼‰
  - `input`
    - `relative`: åˆ†å‰²çª—å£çš„ç›¸å¯¹ä½ç½®ï¼ˆ`editor`/`win`ï¼‰
    - `position`: åˆ†å‰²çª—å£çš„ä½ç½®ï¼ˆ`top`/`left`/`right`/`bottom`ï¼‰
    - `size`: åˆ†å‰²çª—å£çš„æ¯”ä¾‹ï¼ˆé»˜è®¤æ˜¯25%ï¼‰
    - `enter`: æ˜¯å¦è‡ªåŠ¨è¿›å…¥çª—å£
  - `output`
    - `relative`: åŒ`input`
    - `position`: åŒ`input`
    - `size`: åŒ`input`
    - `enter`: åŒ`input`

- `side_by_side_handler`çš„`opts`ä¸­ä½ è¿˜å¯ä»¥å®šä¹‰:
  - `left` å·¦çª—å£
    - `title`: çª—å£çš„æ ‡é¢˜
    - `focusable`: æ˜¯å¦å…è®¸çª—å£è·å¾—ç„¦ç‚¹
    - `border`
    - `win_options`
  - `right` å³çª—å£
    - `title`: çª—å£çš„æ ‡é¢˜
    - `focusable`: æ˜¯å¦å…è®¸çª—å£è·å¾—ç„¦ç‚¹
    - `border`
    - `win_options`

- `flexi_handler`çš„`opts`ä¸­ä½ è¿˜å¯ä»¥å®šä¹‰:
  - `exit_on_move`: æ˜¯å¦åœ¨å…‰æ ‡ç§»åŠ¨æ—¶å…³é—­å¼¹æ€§çª—å£
  - `enter_flexible_window`: æ˜¯å¦åœ¨å¼¹æ€§çª—å£å¼¹å‡ºæ—¶è‡ªåŠ¨è¿›å…¥çª—å£
  - `apply_visual_selection`: æ˜¯å¦è¦åœ¨`prompt`åè¿½åŠ é€‰ä¸­çš„æ–‡æœ¬å†…å®¹

æˆ‘çš„ä¸€äº›AIå·¥å…·é…ç½®:
~~~lua
  {
    "Kurama622/llm.nvim",
    dependencies = { "nvim-lua/plenary.nvim", "MunifTanjim/nui.nvim" },
    cmd = { "LLMSesionToggle", "LLMSelectedTextHandler", "LLMAppHandler" },
    config = function()
      local tools = require("llm.common.tools")
      require("llm").setup({
        app_handler = {
          OptimizeCode = {
            handler = tools.side_by_side_handler,
            -- opts = {
            --   streaming_handler = local_llm_streaming_handler,
            -- },
          },
          TestCode = {
            handler = tools.side_by_side_handler,
            prompt = [[ Write some test cases for the following code, only return the test cases.
            Give the code content directly, do not use code blocks or other tags to wrap it. ]],
            opts = {
              right = {
                title = " Test Cases ",
              },
            },
          },
          OptimCompare = {
            handler = tools.action_handler,
            opts = {
              fetch_key = function()
                return switch("enable_gpt")
              end,
              url = "https://models.inference.ai.azure.com/chat/completions",
              model = "gpt-4o",
              api_type = "openai",
            },
          },

          Translate = {
            handler = tools.qa_handler,
            opts = {
              fetch_key = function()
                return switch("enable_glm")
              end,
              url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
              model = "glm-4-flash",
              api_type = "zhipu",

              component_width = "60%",
              component_height = "50%",
              query = {
                title = " ó°Š¿ Trans ",
                hl = { link = "Define" },
              },
              input_box_opts = {
                size = "15%",
                win_options = {
                  winhighlight = "Normal:Normal,FloatBorder:FloatBorder",
                },
              },
              preview_box_opts = {
                size = "85%",
                win_options = {
                  winhighlight = "Normal:Normal,FloatBorder:FloatBorder",
                },
              },
            },
          },

          -- check siliconflow's balance
          UserInfo = {
            handler = function()
              local key = os.getenv("LLM_KEY")
              local res = tools.curl_request_handler(
                "https://api.siliconflow.cn/v1/user/info",
                { "GET", "-H", string.format("'Authorization: Bearer %s'", key) }
              )
              if res ~= nil then
                print("balance: " .. res.data.balance)
              end
            end,
          },
          WordTranslate = {
            handler = tools.flexi_handler,
            prompt = "Translate the following text to Chinese, please only return the translation",
            opts = {
              fetch_key = function()
                return switch("enable_glm")
              end,
              url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
              model = "glm-4-flash",
              api_type = "zhipu",
              args = [=[return string.format([[curl %s -N -X POST -H "Content-Type: application/json" -H "Authorization: Bearer %s" -d '%s']], url, LLM_KEY, vim.fn.json_encode(body))]=],
              exit_on_move = true,
              enter_flexible_window = false,
            },
          },
          CodeExplain = {
            handler = tools.flexi_handler,
            prompt = "Explain the following code, please only return the explanation, and answer in Chinese",
            opts = {
              fetch_key = function()
                return switch("enable_glm")
              end,
              url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
              model = "glm-4-flash",
              api_type = "zhipu",
              enter_flexible_window = true,
            },
          },
          CommitMsg = {
            handler = tools.flexi_handler,
            prompt = function()
              return string.format(
                [[You are an expert at following the Conventional Commit specification. Given the git diff listed below, please generate a commit message for me:
1. Start with an action verb (e.g., feat, fix, refactor, chore, etc.), followed by a colon.
2. Briefly mention the file or module name that was changed.
3. Describe the specific changes made.

Examples:
- feat: update common/util.py, added test cases for util.py
- fix: resolve bug in user/auth.py related to login validation
- refactor: optimize database queries in models/query.py

Based on this format, generate appropriate commit messages. Respond with message only. DO NOT format the message in Markdown code blocks, DO NOT use backticks:

```diff
%s
```
]],
                vim.fn.system("git diff --no-ext-diff --staged")
              )
            end,
            opts = {
              fetch_key = function()
                return switch("enable_glm")
              end,
              url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
              model = "glm-4-flash",
              api_type = "zhipu",
              enter_flexible_window = true,
              apply_visual_selection = false,
            },
          },
        },
    })
    end,
    keys = {
      { "<leader>ac", mode = "n", "<cmd>LLMSessionToggle<cr>" },
      { "<leader>ts", mode = "x", "<cmd>LLMAppHandler WordTranslate<cr>" },
      { "<leader>ae", mode = "v", "<cmd>LLMAppHandler CodeExplain<cr>" },
      { "<leader>at", mode = "n", "<cmd>LLMAppHandler Translate<cr>" },
      { "<leader>tc", mode = "x", "<cmd>LLMAppHandler TestCode<cr>" },
      { "<leader>ao", mode = "x", "<cmd>LLMAppHandler OptimCompare<cr>" },
      { "<leader>au", mode = "n", "<cmd>LLMAppHandler UserInfo<cr>" },
      { "<leader>ag", mode = "n", "<cmd>LLMAppHandler CommitMsg<cr>" },
      -- { "<leader>ao", mode = "x", "<cmd>LLMAppHandler OptimizeCode<cr>" },
    },
  },
~~~

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹

æœ¬åœ°å¤§æ¨¡å‹éœ€è¦è‡ªå®šä¹‰è§£æå‡½æ•°ï¼Œå¯¹äºæµå¼è¾“å‡ºï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªå®šä¹‰çš„`streaming_handler`ï¼›å¯¹äºä¸€æ¬¡æ€§è¿”å›è¾“å‡ºç»“æœçš„AIå·¥å…·ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªå®šä¹‰çš„`parse_handler`

ä¸‹é¢æ˜¯`ollama`è¿è¡Œ`llama3.2:1b`çš„æ ·ä¾‹
```lua
local function local_llm_streaming_handler(chunk, line, assistant_output, bufnr, winid, F)
  if not chunk then
    return assistant_output
  end
  local tail = chunk:sub(-1, -1)
  if tail:sub(1, 1) ~= "}" then
    line = line .. chunk
  else
    line = line .. chunk
    local status, data = pcall(vim.fn.json_decode, line)
    if not status or not data.message.content then
      return assistant_output
    end
    assistant_output = assistant_output .. data.message.content
    F.WriteContent(bufnr, winid, data.message.content)
    line = ""
  end
  return assistant_output
end

local function local_llm_parse_handler(chunk)
  local assistant_output = chunk.message.content
  return assistant_output
end

return {
  {
    "Kurama622/llm.nvim",
    dependencies = { "nvim-lua/plenary.nvim", "MunifTanjim/nui.nvim" },
    cmd = { "LLMSesionToggle", "LLMSelectedTextHandler" },
    config = function()
      require("llm").setup({
        url = "http://localhost:11434/api/chat", -- your url
        model = "llama3.2:1b",

        streaming_handler = local_llm_streaming_handler,
        app_handler = {
          WordTranslate = {
            handler = tools.flexi_handler,
            prompt = "Translate the following text to Chinese, please only return the translation",
            opts = {
              parse_handler = local_llm_parse_handler,
              exit_on_move = true,
              enter_flexible_window = false,
            },
          },
        }
      })
    end,
    keys = {
      { "<leader>ac", mode = "n", "<cmd>LLMSessionToggle<cr>" },
    },
  }
}
```

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

## é»˜è®¤å¿«æ·é”®

- æµ®åŠ¨çª—å£é£æ ¼ä¸‹çš„å¿«æ·é”®

| çª—å£         | æŒ‰é”®         | æ¨¡å¼     | æè¿°                    |
| ------------ | ------------ | -------- | ----------------------- |
| Input        | `ctrl+g`     | `i`      | æäº¤ä½ çš„é—®é¢˜            |
| Input        | `ctrl+c`     | `i`      | å–æ¶ˆæœ¬è½®å¯¹è¯            |
| Input        | `ctrl+r`     | `i`      | é‡æ–°å‘èµ·æœ¬è½®å¯¹è¯        |
| Input        | `ctrl+j`     | `i`      | åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªä¼šè¯å†å²    |
| Input        | `ctrl+k`     | `i`      | åˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªä¼šè¯å†å²    |
| Output+Input | `<leader>ac` | `n`      | æ‰“å¼€/éšè—å¯¹è¯ç•Œé¢       |
| Output+Input | `<esc>`      | `n`      | å…³é—­å¯¹è¯ç•Œé¢            |

- åˆ†å‰²çª—å£é£æ ¼ä¸‹çš„å¿«æ·é”®

| çª—å£         | æŒ‰é”®         | æ¨¡å¼     | æè¿°                    |
| ------------ | ------------ | -------- | ----------------------- |
| Input        | `<cr>`       | `n`      | æäº¤ä½ çš„é—®é¢˜            |
| Output       | `i`          | `n`      | æ‰“å¼€è¾“å…¥çª—å£            |
| Output       | `ctrl+c`     | `n`      | å–æ¶ˆæœ¬è½®å¯¹è¯            |
| Output       | `ctrl+r`     | `n`      | é‡æ–°å‘èµ·æœ¬è½®å¯¹è¯        |

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

## ä½œè€…çš„é…ç½®æ–‡ä»¶

[plugins/llm.lua](https://github.com/Kurama622/.lazyvim/blob/main/lua/plugins/llm.lua)

---

## å¸¸è§é—®é¢˜

### windowsçš„curlä½¿ç”¨æ ¼å¼ä¸linuxä¸ä¸€æ ·ï¼Œllm.nvimé»˜è®¤çš„è¯·æ±‚æ ¼å¼ï¼Œwindowsä¸‹ä¼šæœ‰é—®é¢˜

ä½¿ç”¨è‡ªå®šä¹‰è¯·æ±‚æ ¼å¼

- åŸºç¡€å¯¹è¯åŠŸèƒ½ä»¥åŠéƒ¨åˆ†AIå·¥å…·ï¼ˆä½¿ç”¨æµå¼è¾“å‡ºï¼‰è‡ªå®šä¹‰è¯·æ±‚æ ¼å¼

  å®šä¹‰argså‚æ•°ï¼Œä¸promptåŒå±‚çº§
  ```lua
  --[[ custom request args ]]
  args = [[return {url, "-N", "-X", "POST", "-H", "Content-Type: application/json", "-H", authorization, "-d", vim.fn.json_encode(body)}]],
  ```

- AIå·¥å…·ï¼ˆä½¿ç”¨éæµå¼è¾“å‡ºï¼‰è‡ªå®šä¹‰è¯·æ±‚æ ¼å¼

  åœ¨`opts`ä¸­å®šä¹‰args
  ```lua
    WordTranslate = {
      handler = tools.flexi_handler,
      prompt = "Translate the following text to Chinese, please only return the translation",
      opts = {
        fetch_key = function()
          return switch("enable_glm")
        end,
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions",
        model = "glm-4-flash",
        api_type = "zhipu",
        args = [=[return string.format([[curl %s -N -X POST -H "Content-Type: application/json" -H "Authorization: Bearer %s" -d '%s']], url, LLM_KEY, vim.fn.json_encode(body))]=],
        exit_on_move = true,
        enter_flexible_window = false,
      },
    },
  ```

> [!NOTE]
> éœ€è¦æ ¹æ®ä½ çš„å®é™…æƒ…å†µå»ä¿®æ”¹args

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### å¤šä¸ªå¤§æ¨¡å‹åˆ‡æ¢ï¼Œé¢‘ç¹æ›´æ”¹LLM_KEYçš„å€¼å¾ˆéº»çƒ¦ï¼Œè€Œä¸”æˆ‘ä¸æƒ³åœ¨Neovimçš„é…ç½®æ–‡ä»¶ä¸­æš´éœ²æˆ‘çš„Key

- åˆ›å»ºä¸€ä¸ª`.env`æ–‡ä»¶ï¼Œä¸“é—¨ä¿å­˜ä½ çš„å„ç§Keyã€‚æ³¨æ„ï¼šæ­¤æ–‡ä»¶ä¸è¦ä¸Šä¼ Github

- åœ¨zshrcæˆ–è€…bashrcä¸­åŠ è½½`.env`ï¼Œå¹¶å®šä¹‰ä¸€äº›å‡½æ•°ï¼Œç”¨äºåˆ‡æ¢ä¸åŒçš„å¤§æ¨¡å‹
  ```bash
  source ~/.config/zsh/.env

  export ACCOUNT=$WORKERS_AI_ACCOUNT
  export LLM_KEY=$SILICONFLOW_TOKEN

  enable_workers_ai() {
    export LLM_KEY=$WORKERS_AI_KEY
  }

  enable_glm() {
    export LLM_KEY=$GLM_KEY
  }

  enable_kimi() {
    export LLM_KEY=$KIMI_KEY
  }

  enable_gpt() {
    export LLM_KEY=$GITHUB_TOKEN
  }

  enable_siliconflow() {
    export LLM_KEY=$SILICONFLOW_TOKEN
  }
  enable_openai() {
    export LLM_KEY=$OPENAI_KEY
  }
  enable_local() {
    export LLM_KEY=$LOCAL_LLM_KEY
  }
  ```

- æœ€ååœ¨llm.nvimé…ç½®æ–‡ä»¶ä¸­ï¼Œæ·»åŠ `switch`å‡½æ•°
  ```lua
  local function switch(shell_func)
    -- [LINK] https://github.com/Kurama622/dotfiles/blob/main/zsh/module/func.zsh
    local p = io.popen(string.format("source ~/.config/zsh/module/func.zsh; %s; echo $LLM_KEY", shell_func))
    local key = p:read()
    p:close()
    return key
  end
  ```
  é€šè¿‡`fetch_key`å®ŒæˆKeyçš„åˆ‡æ¢
  ```lua
    fetch_key = function()
      return switch("enable_glm")
    end,
  ```

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### ä¸åŒè§£æå‡½æ•°çš„ä¼˜å…ˆçº§

  AIå·¥å…·é…ç½®çš„`streaming_handler`æˆ–è€…`parse_handler` > AIå·¥å…·é…ç½®çš„`api_type` > ä¸»é…ç½®çš„`streaming_handler`æˆ–è€…`parse_handler` > ä¸»é…ç½®çš„`api_type`

[â¬† è¿”å›ç›®å½•](#ç›®å½•)

### AIç”Ÿæˆgit commitä¿¡æ¯çš„åŠŸèƒ½å¦‚ä½•ä¸lazygité›†æˆåœ¨ä¸€èµ·?

  ```lua
    {
      "kdheepak/lazygit.nvim",
      lazy = true,
      cmd = {
        "LazyGit",
        "LazyGitConfig",
        "LazyGitCurrentFile",
        "LazyGitFilter",
        "LazyGitFilterCurrentFile",
      },
      -- optional for floating window border decoration
      dependencies = {
        "nvim-lua/plenary.nvim",
      },
      config = function()
        vim.keymap.set("t", "<C-c>", function()
          vim.api.nvim_win_close(vim.api.nvim_get_current_win(), true)
          vim.api.nvim_command("LLMAppHandler CommitMsg")
        end, { desc = "AI Commit Msg" })
      end,
    }
  ```

[â¬† è¿”å›ç›®å½•](#ç›®å½•)
